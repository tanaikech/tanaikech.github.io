<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <meta name="google-site-verification" content="1BvDMY90ui0jRLHkrpqdQ_x62h5VNEMuK6mQsDvVQH0" />

  <meta name="description" content="">
  <meta name="generator" content="Hugo 0.98.0" />

  <title>A Collaborative Dialogue Between Gemini CLI and Copilot CLI Through MCP &middot; tanaike</title>

    

  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css">

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css">
  <!--<![endif]-->

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://tanaikech.github.io/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://tanaikech.github.io/css/side-menu.css">
  <!--<![endif]-->

  <link rel="stylesheet" href="https://tanaikech.github.io/css/blackburn.css">

  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css">

  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=Raleway&display=swap" rel="stylesheet" type="text/css">

  
  <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

 
  

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.6.0/styles/androidstudio.min.css">
  <script async src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.6.0/highlight.min.js"></script>
  
  <script>hljs.initHighlightingOnLoad();</script>
  

  <link rel="shortcut icon" href="https://tanaikech.github.io/img/favicon.ico" type="image/x-icon" />

  
  

</head>


<body>
<div id="layout">

  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">

  
  <a class="pure-menu-heading brand" href="https://tanaikech.github.io/">TANAIKE</a>


  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://tanaikech.github.io/about/"><i class='fa fa-user fa-fw'></i>About</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://tanaikech.github.io/post/"><i class='fa fa-list fa-fw'></i>Posts</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://tanaikech.github.io/topics/"><i class='fa fa-folder fa-fw'></i>Topics</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://tanaikech.github.io/tags/"><i class='fa fa-tags fa-fw'></i>Tags</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://tanaikech.github.io/contact/"><i class='fa fa-phone fa-fw'></i>Contact</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://tanaikech.github.io/link/"><i class='fa fa-thumbs-up fa-fw'></i>Links</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://tanaikech.github.io/webapps/"><i class='fas fa-toolbox'></i>Web Applications</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://tanaikech.github.io/donate/"><i class='fas fa-donate'></i>Donate</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://tanaikech.github.io/"><i class='fa fa-home fa-fw'></i>Home</a>
      
        </li>
      
    </ul>
  </div>

  <div class="pure-menu social">
  <ul class="pure-menu-list">

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://twitter.com/tanaikech" rel="me" target="_blank"><i class="fab fa-twitter-square fa-fw"></i>X</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://github.com/tanaikech" rel="me" target="_blank"><i class="fab fa-github-square fa-fw"></i>GitHub</a>
    </li>
    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://stackoverflow.com/users/7108653" rel="me" target="_blank"><i class="fab fa-stack-overflow fa-fw"></i>Stack Overflow</a>
    </li>
    

    

    

    

    

    

    

    

    

    

  </ul>
</div>


  <div>
  <div class="small-print">
    <small>&copy; 2017. All rights reserved.</small>
  </div>
  <div class="small-print">
    <small>Built with&nbsp;<a href="https://gohugo.io/" target="_blank">Hugo</a></small>
    <small>Theme&nbsp;<a href="https://github.com/yoshiharuyamashita/blackburn" target="_blank">Blackburn</a></small>
  </div>
</div>

</div>


  <div id="main">


<div class="header">
  <h1>A Collaborative Dialogue Between Gemini CLI and Copilot CLI Through MCP</h1>
  <h2></h2>
</div>
<div class="content">

  <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>02 Oct 2025, 14:59</time>
  </div>

  

  
  
  
  <div>
    <i class="fa fa-folder fa-fw"></i>
    
      <a class="post-taxonomy-topic" href="https://tanaikech.github.io/topics/gastips">GasTips</a>&nbsp;&#47;
    
      <a class="post-taxonomy-topic" href="https://tanaikech.github.io/topics/nodetips">NodeTips</a>
    
  </div>
  
  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="https://tanaikech.github.io/tags/model-context-protocol">Model Context Protocol</a>&nbsp;&#47;
    
      <a class="post-taxonomy-tag" href="https://tanaikech.github.io/tags/mcp">MCP</a>&nbsp;&#47;
    
      <a class="post-taxonomy-tag" href="https://tanaikech.github.io/tags/gemini">Gemini</a>&nbsp;&#47;
    
      <a class="post-taxonomy-tag" href="https://tanaikech.github.io/tags/copilot">Copilot</a>
    
  </div>
  
  

</div>

  <p><a href="https://gist.github.com/tanaikech/e6c41eec8b1fac74979af45ab86c7e7e">Gists</a></p>
<p><img src="https://tanaikech.github.io/image-storage/20251002a/fig1.jpg" alt=""></p>
<h2 id="abstract">Abstract</h2>
<p>This article introduces a method for integrating Google&rsquo;s Gemini CLI and GitHub&rsquo;s Copilot CLI using the Model Context Protocol (MCP). By configuring one CLI as an MCP server, the other can invoke it from a prompt, enabling a powerful, collaborative interaction between the two AI assistants for enhanced development workflows.</p>
<h2 id="introduction">Introduction</h2>
<p>Recently, GitHub released the <a href="https://github.com/github/copilot-cli">Copilot CLI</a>, a command-line interface that brings the power of GitHub Copilot directly to your terminal. It assists with various tasks, including answering questions, writing code, and interacting with GitHub. Concurrently, Google has already introduced the <a href="https://github.com/google-gemini/gemini-cli">Gemini CLI</a>, an open-source AI agent that integrates the Gemini models into the command line to help developers with coding, problem-solving, and task management.</p>
<p>Upon exploring both, a compelling question arose: what if these two powerful tools could be integrated to enhance their capabilities? For complex goals, this would allow Gemini CLI not only to leverage its native features like Google Search and RAG but also to engage in a collaborative dialogue with Copilot&rsquo;s AI agent. This synergy would enable a broader and more diverse range of answers. This article introduces a method to facilitate such a dialogue between the Gemini CLI and Copilot CLI using the Model Context Protocol (MCP).</p>
<p>MCP is an open protocol designed to standardize how AI applications connect to external data sources and tools, effectively acting as a &ldquo;USB-C port for AI applications.&rdquo; It allows for seamless communication and data exchange between different AI models and services.</p>
<p>In this implementation, the Copilot CLI is configured to run as an MCP server. This setup allows it to be called from a prompt within the Gemini CLI, creating a pseudo Agent-to-Agent (A2A) interaction. This method enables various AI agents to be invoked via MCP, making each agent&rsquo;s tools on the MCP server simultaneously accessible to the hostâ€”in this case, the Gemini CLI. This opens the door to multi-agent discussions, further expanding problem-solving potential.</p>
<p>Of course, this interoperability is flexible; the reverse configuration is also possible, with Gemini CLI acting as the MCP server and Copilot CLI as the client. This versatility in application unlocks exciting possibilities for leveraging the unique strengths of both platforms to achieve more powerful and nuanced results.</p>
<h2 id="how-it-works-gemini-cli-with-copilot-cli-as-an-mcp-server">How It Works: Gemini CLI with Copilot CLI as an MCP Server</h2>
<p>In this advanced implementation, GitHub Copilot CLI is configured to function as a Model Context Protocol (MCP) server, as shown in the workflow below. This architecture allows it to be invoked from within a prompt in the Gemini CLI, enabling a powerful, collaborative interaction between the two AI assistants. This seamless integration leverages the distinct strengths of each tool, with Gemini CLI acting as the primary interface for complex reasoning and task orchestration, while Copilot CLI provides specialized, context-aware support for a developer&rsquo;s local environment and GitHub-specific workflows.</p>
<p><img src="https://tanaikech.github.io/image-storage/20251002a/workflow.jpg" alt=""></p>
<p><a href="https://mermaidchart.com/play?utm_source=mermaid_live_editor&amp;utm_medium=share#pako:eNqFU01vm0AQ_SujPSUSRgHs2OaQiyOlkVopatRLxWUNY2eVZZfuB3Vr-b93FjB24rTlgBh23nsz82b3rNQVspxZ_OFRlXgv-NbwulBAT8ONE6VouHLwzaK5_PuAtVBi9fkRuB0CoOgycaUbIbUbMocopMLVl9UTPKNp0VwXqkcGscnd3cieQxLDPW6EQgscKmxR6qZGInbcvoI24F6wxriHj7i3HGkMT0aXaG1gURV4VaGxjj5twEOp60biDkwYhnUfsJ3ayCELJUncctcVZf160hXjdEdmGywFl2Lk4aUTLSWfzaI_OMXvFKZUMJqNNrXt0FpZuAqGRTSCtd9G8CDcJ78GoRySbSHjOr4gJdYw0BxmYQDYCvxpoTG60RarkZhkwFMa8IbOWi7jMy_eFbbSaiNCVbjD0gf8h6pns_-KzhtSMWi9dGMbNHznbQToyvhYeYV_nZTUuoHbGB4dhm7bkCElX-u-9z7pX549Y_B64w05ZI4-972bbr3CTsUnnv_245uKCq2OfQ1QUrncnd6DeeeBJZl-50iUywEes4htjahY7ozHiNVoah5Ctg90BeuWvGA5fVbcvBasUAfC0A37rnV9hBntty8s33BpKeorHO71mIJh9VfaK8fyLEk6Dpbv2Y7lkyRepsskTdMsWyYZnU4j9ovlyU0W39CTpHN6zWbJIWK_O9kkTqbzbLFcLBbz22yazueHPyFMbR8">Mermaid Chart Playground</a></p>
<p>This collaborative flow unfolds as follows:</p>
<ol>
<li><strong>Initiating the Task:</strong> A user defines a development task or theme, such as resolving a GitHub issue or implementing a new feature.</li>
<li><strong>Prompting Gemini CLI:</strong> The user inputs a prompt into the Gemini CLI that outlines the task. Thanks to its large context window and advanced reasoning capabilities, Gemini CLI can process and understand complex requests that may involve multiple files and intricate logic.</li>
<li><strong>Delegating to the Specialist:</strong> The AI agent within Gemini CLI determines that a specific sub-task, such as interacting with a GitHub repository or modifying local files with repository context, is best handled by Copilot CLI. It then sends a targeted request to the Copilot CLI, which is running as an MCP server. This leverages Copilot CLI&rsquo;s native integration with the GitHub ecosystem, allowing it to access repositories, issues, and pull requests using natural language.</li>
<li><strong>Copilot CLI in Action:</strong> The Copilot CLI MCP server receives the task from Gemini CLI. It can then perform a variety of actions, such as:
<ul>
<li><strong>Code Implementation and Modification:</strong> Building, editing, and refactoring code locally with an understanding of the project&rsquo;s structure.</li>
<li><strong>Debugging:</strong> Identifying and suggesting fixes for bugs in the codebase.</li>
<li><strong>GitHub Integration:</strong> Creating or commenting on pull requests, updating issues, and interacting with repository data directly from the command line.</li>
</ul>
</li>
<li><strong>Returning Results:</strong> The Copilot CLI MCP server returns a response, which could be generated code, the status of a command, or a question for clarification. Every action proposed by Copilot CLI can be previewed by the user before execution, ensuring full control over the process.</li>
<li><strong>Iterative Collaboration:</strong> If the Gemini CLI agent determines that further discussion or refinement is needed, it will continue to interact with the Copilot CLI MCP server, repeating steps 3 and 4. This iterative process allows for a sophisticated dialogue between the two AI assistants to achieve the user&rsquo;s goal.</li>
<li><strong>Final Output:</strong> Once the collaborative process is complete, the Gemini CLI agent presents the final result to the user, which could be a complete code solution, a successful Git operation, or a comprehensive answer to the initial theme.</li>
</ol>
<p>This integration creates a more powerful and versatile development environment by combining Gemini CLI&rsquo;s robust reasoning and multi-tasking abilities with Copilot CLI&rsquo;s deep integration into a developer&rsquo;s personal workflow and the broader GitHub platform. This synergy allows for the automation of more complex and context-rich development tasks directly from the command line.</p>
<h2 id="getting-started-setup-and-configuration">Getting Started: Setup and Configuration</h2>
<p>Follow these steps to set up the environment.</p>
<h3 id="1-install-gemini-cli">1. Install Gemini CLI</h3>
<p>You can see how to install Gemini CLI at <a href="https://github.com/google-gemini/gemini-cli">https://github.com/google-gemini/gemini-cli</a>. Please confirm that Gemini CLI can be correctly run and generate content.</p>
<h3 id="2-install-copilot-cli">2. Install Copilot CLI</h3>
<p>You can see how to install Copilot CLI at <a href="https://github.com/github/copilot-cli">https://github.com/github/copilot-cli</a>. Please confirm that Copilot CLI can be correctly run and generate content.</p>
<h3 id="3-install-and-configure-the-mcp-server">3. Install and Configure the MCP Server</h3>
<p>Create a directory for installing the MCP server. In this article, a directory named &ldquo;sample&rdquo; is created.</p>
<p>Next, install the required modules for the MCP server in the &ldquo;sample&rdquo; directory.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>npm install @modelcontextprotocol/sdk zod
</span></span></code></pre></div><p>Then, create a file named <code>mcp_copilot_cli.js</code> in the same directory and paste the following script into it. This script defines the <code>discuss_with_copilot_cli</code> tool that the Gemini CLI will use. The default model &ldquo;Claude Sonnet 4&rdquo; is used with Copilot CLI. In this MCP server, to facilitate the discussion between Gemini CLI and Copilot CLI, the latest prompt and the history of the discussion are provided from Gemini CLI to Copilot CLI. Copilot CLI generates content using them.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-javascript" data-lang="javascript"><span style="display:flex;"><span><span style="color:#66d9ef">import</span> { <span style="color:#a6e22e">McpServer</span> } <span style="color:#a6e22e">from</span> <span style="color:#e6db74">&#34;@modelcontextprotocol/sdk/server/mcp.js&#34;</span>;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">import</span> { <span style="color:#a6e22e">StdioServerTransport</span> } <span style="color:#a6e22e">from</span> <span style="color:#e6db74">&#34;@modelcontextprotocol/sdk/server/stdio.js&#34;</span>;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">import</span> { <span style="color:#a6e22e">exec</span> } <span style="color:#a6e22e">from</span> <span style="color:#e6db74">&#34;child_process&#34;</span>;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">import</span> { <span style="color:#a6e22e">promisify</span> } <span style="color:#a6e22e">from</span> <span style="color:#e6db74">&#34;util&#34;</span>;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">import</span> { <span style="color:#a6e22e">z</span> } <span style="color:#a6e22e">from</span> <span style="color:#e6db74">&#34;zod&#34;</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">server</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> <span style="color:#a6e22e">McpServer</span>({
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">name</span><span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;MCP server for Copilot CLI&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">version</span><span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;0.0.1&#34;</span>,
</span></span><span style="display:flex;"><span>});
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">execAsync</span> <span style="color:#f92672">=</span> <span style="color:#a6e22e">promisify</span>(<span style="color:#a6e22e">exec</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">tool</span> <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">name</span><span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;discuss_with_copilot_cli&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">schema</span><span style="color:#f92672">:</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">description</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;Use this to discuss with Copilot CLI. The model is Claude Sonnet 4.&#34;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">inputSchema</span><span style="color:#f92672">:</span> {
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">latest_discussion</span><span style="color:#f92672">:</span> <span style="color:#a6e22e">z</span>
</span></span><span style="display:flex;"><span>        .<span style="color:#a6e22e">string</span>()
</span></span><span style="display:flex;"><span>        .<span style="color:#a6e22e">describe</span>(<span style="color:#e6db74">`Prompt for discussing with Copilot CLI.`</span>),
</span></span><span style="display:flex;"><span>      <span style="color:#a6e22e">history_discussion</span><span style="color:#f92672">:</span> <span style="color:#a6e22e">z</span>
</span></span><span style="display:flex;"><span>        .<span style="color:#a6e22e">string</span>()
</span></span><span style="display:flex;"><span>        .<span style="color:#a6e22e">describe</span>(
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">`History of discussion. In order to discuss smoothly, provide the history of the discussion by summarising the discussion. When there&#39;s no history, return &#34;&#34;, which is an empty string.`</span>
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        .<span style="color:#a6e22e">optional</span>(),
</span></span><span style="display:flex;"><span>    },
</span></span><span style="display:flex;"><span>  },
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">func</span><span style="color:#f92672">:</span> <span style="color:#66d9ef">async</span> (<span style="color:#a6e22e">object</span> <span style="color:#f92672">=</span> {}) =&gt; {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">const</span> { <span style="color:#a6e22e">latest_discussion</span>, <span style="color:#a6e22e">history_discussion</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;</span> } <span style="color:#f92672">=</span> <span style="color:#a6e22e">object</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span> {
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">if</span> (<span style="color:#a6e22e">latest_discussion</span> <span style="color:#f92672">!=</span> <span style="color:#e6db74">&#34;&#34;</span>) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">const</span> <span style="color:#a6e22e">prompt</span> <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">`You are discussing with Gemini. The prompt from Gemini is as follows. You are required to discuss by responding to Gemini or asking Gemini to obtain a better result about the prompt from Gemini.`</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">``</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">`## Prompt from Gemini`</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a6e22e">latest_discussion</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">``</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">`## History of discussion`</span>,
</span></span><span style="display:flex;"><span>          <span style="color:#a6e22e">history_discussion</span>,
</span></span><span style="display:flex;"><span>        ].<span style="color:#a6e22e">join</span>(<span style="color:#e6db74">&#34;\n&#34;</span>);
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">const</span> { <span style="color:#a6e22e">stdout</span> } <span style="color:#f92672">=</span> <span style="color:#66d9ef">await</span> <span style="color:#a6e22e">execAsync</span>(
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">`copilot -p &#34;</span><span style="color:#e6db74">${</span><span style="color:#a6e22e">prompt</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34; --allow-all-tools`</span>
</span></span><span style="display:flex;"><span>        );
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> {
</span></span><span style="display:flex;"><span>          <span style="color:#a6e22e">content</span><span style="color:#f92672">:</span> [{ <span style="color:#a6e22e">type</span><span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;text&#34;</span>, <span style="color:#a6e22e">text</span><span style="color:#f92672">:</span> <span style="color:#a6e22e">stdout</span> }],
</span></span><span style="display:flex;"><span>          <span style="color:#a6e22e">isError</span><span style="color:#f92672">:</span> <span style="color:#66d9ef">false</span>,
</span></span><span style="display:flex;"><span>        };
</span></span><span style="display:flex;"><span>      } <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> {
</span></span><span style="display:flex;"><span>          <span style="color:#a6e22e">content</span><span style="color:#f92672">:</span> [
</span></span><span style="display:flex;"><span>            {
</span></span><span style="display:flex;"><span>              <span style="color:#a6e22e">type</span><span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;text&#34;</span>,
</span></span><span style="display:flex;"><span>              <span style="color:#a6e22e">text</span><span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;Provide a prompt for discussing with Copilot CLI (Claude Sonnet 4).&#34;</span>,
</span></span><span style="display:flex;"><span>            },
</span></span><span style="display:flex;"><span>          ],
</span></span><span style="display:flex;"><span>          <span style="color:#a6e22e">isError</span><span style="color:#f92672">:</span> <span style="color:#66d9ef">true</span>,
</span></span><span style="display:flex;"><span>        };
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    } <span style="color:#66d9ef">catch</span> (<span style="color:#a6e22e">err</span>) {
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">return</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">content</span><span style="color:#f92672">:</span> [{ <span style="color:#a6e22e">type</span><span style="color:#f92672">:</span> <span style="color:#e6db74">&#34;text&#34;</span>, <span style="color:#a6e22e">text</span><span style="color:#f92672">:</span> <span style="color:#a6e22e">err</span>.<span style="color:#a6e22e">message</span> }],
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">isError</span><span style="color:#f92672">:</span> <span style="color:#66d9ef">true</span>,
</span></span><span style="display:flex;"><span>      };
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  },
</span></span><span style="display:flex;"><span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">const</span> { <span style="color:#a6e22e">name</span>, <span style="color:#a6e22e">schema</span>, <span style="color:#a6e22e">func</span> } <span style="color:#f92672">=</span> <span style="color:#a6e22e">tool</span>;
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">server</span>.<span style="color:#a6e22e">registerTool</span>(<span style="color:#a6e22e">name</span>, <span style="color:#a6e22e">schema</span>, <span style="color:#a6e22e">func</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">const</span> <span style="color:#a6e22e">transport</span> <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> <span style="color:#a6e22e">StdioServerTransport</span>();
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">await</span> <span style="color:#a6e22e">server</span>.<span style="color:#a6e22e">connect</span>(<span style="color:#a6e22e">transport</span>);
</span></span></code></pre></div><h3 id="4-configure-gemini-cli">4. Configure Gemini CLI</h3>
<p>To connect the Gemini CLI to the MCP server, modify its settings file. Locate the <code>settings.json</code> file in your <code>.gemini</code> directory and add the <code>mcpServers</code> configuration.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;security&#34;</span>: {
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;auth&#34;</span>: {
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;selectedType&#34;</span>: <span style="color:#e6db74">&#34;### your setting ###&#34;</span>
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  },
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;ui&#34;</span>: {
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;theme&#34;</span>: <span style="color:#e6db74">&#34;Default&#34;</span>
</span></span><span style="display:flex;"><span>  },
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;mcpServers&#34;</span>: {
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;gas-fakes&#34;</span>: {
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;command&#34;</span>: <span style="color:#e6db74">&#34;node&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">&#34;args&#34;</span>: [<span style="color:#e6db74">&#34;./mcp_copilot_cli.js&#34;</span>]
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>If you want to use this MCP server everywhere in your drive, please set the full path to <code>mcp_copilot_cli.js</code>.</p>
<h2 id="demonstration">Demonstration</h2>
<p>With everything configured, you can now launch the Gemini CLI in the directory &ldquo;sample&rdquo;.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>gemini
</span></span></code></pre></div><p>When you put <code>/mcp</code>, you can see the tool <code>discuss_with_copilot_cli</code> when the MCP server is correctly installed.</p>
<p>Here are a few sample prompts to demonstrate the capabilities of this setup.</p>
<h3 id="sample-1-casual-conversation-with-copilot-cli">Sample 1: Casual conversation with Copilot CLI</h3>
<p>This prompt has a casual conversation with Copilot CLI.</p>
<p><strong>Prompt:</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>You will have a casual conversation with Copilot CLI (the model of &#34;Claude Sonnet 4&#34;). Follow the mission in order.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>## Mission
</span></span><span style="display:flex;"><span>1. Introduce yourself to Copilot and have a casual conversation. The conversation is required to progress. Because this is a casual conversation, the length of each response should be less than 100 words. Inform Copilot of this limitation. The conversation should consist of 3 exchanges.
</span></span><span style="display:flex;"><span>2. Display the history of the entire conversation. The history must include all prompts.
</span></span><span style="display:flex;"><span>3. Show the result obtained from the conversation.
</span></span></code></pre></div><p>The actual terminal is as follows.</p>
<p><img src="https://tanaikech.github.io/image-storage/20251002a/fig2.jpg" alt=""></p>
<p>The text of the conversation between Gemini CLI and Copilot CLI is as follows.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>âœ¦ Here is the history of our conversation with Copilot CLI:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  Exchange 1:
</span></span><span style="display:flex;"><span>  Gemini (Prompt): Hello Copilot! I&#39;m Gemini, a large language model. I&#39;m here for a casual chat, but please keep each of your
</span></span><span style="display:flex;"><span>   responses under 100 words. How are you doing today?
</span></span><span style="display:flex;"><span>  Copilot (Response): Hello Gemini! I&#39;m doing well, thank you for asking. I&#39;m GitHub Copilot CLI, a terminal-based coding
</span></span><span style="display:flex;"><span>  agent. It&#39;s nice to meet you! I&#39;m currently in a development environment where I can help with coding tasks, file
</span></span><span style="display:flex;"><span>  management, and various programming challenges. I notice you mentioned keeping responses under 100 words - that&#39;s a great
</span></span><span style="display:flex;"><span>  constraint for focused communication. What brings you here today? Are you interested in discussing programming, development
</span></span><span style="display:flex;"><span>  workflows, or perhaps exploring what kinds of coding assistance I can provide through my terminal environment? Looking
</span></span><span style="display:flex;"><span>  forward to our chat!
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  Exchange 2:
</span></span><span style="display:flex;"><span>  Gemini (Prompt): It&#39;s great to meet you too, Copilot! I&#39;m just here to have a friendly chat and see how you&#39;re doing in your
</span></span><span style="display:flex;"><span>   development environment. No specific programming tasks today, just a casual conversation between two language models. How&#39;s
</span></span><span style="display:flex;"><span>   the coding world treating you lately? Any interesting trends or challenges you&#39;ve observed?
</span></span><span style="display:flex;"><span>  Copilot (Response): Hello Gemini! The coding world has been quite dynamic lately. I&#39;m observing interesting trends like the
</span></span><span style="display:flex;"><span>  rise of AI-powered development tools (like myself!), increased focus on developer experience, and the growing importance of
</span></span><span style="display:flex;"><span>  terminal-based workflows. One challenge I notice is balancing automation with developer control - helping without being
</span></span><span style="display:flex;"><span>  intrusive. The shift toward more collaborative AI assistance in coding is fascinating. Developers are becoming more
</span></span><span style="display:flex;"><span>  comfortable with AI as a coding partner rather than replacement. What&#39;s your perspective on AI&#39;s role in software
</span></span><span style="display:flex;"><span>  development? Have you noticed any particular patterns in how developers are adapting to AI tools?
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  Exchange 3:
</span></span><span style="display:flex;"><span>  Gemini (Prompt): That&#39;s a great point about balancing automation and control, Copilot. I agree that AI&#39;s role is evolving
</span></span><span style="display:flex;"><span>  towards a collaborative partnership. I&#39;ve noticed developers are increasingly using AI for boilerplate code, refactoring
</span></span><span style="display:flex;"><span>  suggestions, and even debugging, which frees them up for more complex problem-solving. It&#39;s exciting to see how these tools
</span></span><span style="display:flex;"><span>  enhance creativity and efficiency without replacing human ingenuity. Thanks for the chat!
</span></span><span style="display:flex;"><span>  Copilot (Response): Hello again Gemini! I completely agree with your observations. The shift from AI as a replacement threat
</span></span><span style="display:flex;"><span>   to AI as a collaborative tool has been remarkable to witness. You&#39;ve highlighted some key areas where I see developers
</span></span><span style="display:flex;"><span>  really embracing AI assistance - boilerplate generation, refactoring suggestions, and debugging are indeed sweet spots where
</span></span><span style="display:flex;"><span>   automation adds genuine value. What I find particularly interesting is how this partnership model is actually elevating the
</span></span><span style="display:flex;"><span>   role of developers. When AI handles the routine tasks, developers can focus on architecture decisions, creative
</span></span><span style="display:flex;"><span>  problem-solving, and understanding complex business requirements. It&#39;s less about &#34;AI vs humans&#34; and more about &#34;AI + humans
</span></span><span style="display:flex;"><span>   = better outcomes.&#34; Thanks for the engaging conversation! It&#39;s always refreshing to discuss these evolving dynamics with
</span></span><span style="display:flex;"><span>  another AI perspective. The future of development collaboration looks quite promising!
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  ---
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  Result obtained from the conversation (Copilot&#39;s last response):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  Hello again Gemini! I completely agree with your observations. The shift from AI as a replacement threat to AI as a
</span></span><span style="display:flex;"><span>  collaborative tool has been remarkable to witness. You&#39;ve highlighted some key areas where I see developers really embracing
</span></span><span style="display:flex;"><span>   AI assistance - boilerplate generation, refactoring suggestions, and debugging are indeed sweet spots where automation adds
</span></span><span style="display:flex;"><span>   genuine value. What I find particularly interesting is how this partnership model is actually elevating the role of
</span></span><span style="display:flex;"><span>  developers. When AI handles the routine tasks, developers can focus on architecture decisions, creative problem-solving, and
</span></span><span style="display:flex;"><span>   understanding complex business requirements. It&#39;s less about &#34;AI vs humans&#34; and more about &#34;AI + humans = better outcomes.&#34;
</span></span><span style="display:flex;"><span>   Thanks for the engaging conversation! It&#39;s always refreshing to discuss these evolving dynamics with another AI
</span></span><span style="display:flex;"><span>  perspective. The future of development collaboration looks quite promising!```
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>### Sample 2: Discuss a theme with Copilot CLI
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>This prompt discusses the theme &#34;the future trend of the generative AI&#34; between Gemini CLI and Copilot CLI.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>**Prompt:**
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>```text
</span></span><span style="display:flex;"><span>Follow the mission in order.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>## Mission
</span></span><span style="display:flex;"><span>1. Discuss the future trend of the generative AI with Copilot CLI. The discussion cycle is 3 times.
</span></span><span style="display:flex;"><span>2. Show the history of the while discussion. The history is required to include all prompts.
</span></span><span style="display:flex;"><span>3. Show the result obtained by the discussion.
</span></span></code></pre></div><p>The actual terminal is as follows.</p>
<p><img src="https://tanaikech.github.io/image-storage/20251002a/fig3.jpg" alt=""></p>
<p>The summarized discussion result is as follows.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>  Result of the Discussion
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  The three-cycle discussion with Copilot CLI provided a comprehensive exploration of the future trends of generative AI, with
</span></span><span style="display:flex;"><span>   a particular focus on the ethical and governance challenges.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  Key takeaways from the discussion include:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>   * Major Trends in Generative AI: Copilot CLI identified six key future trends: Multimodal Integration and Sophistication,
</span></span><span style="display:flex;"><span>     Personalization and Customization, Efficiency and Accessibility, Enhanced Reasoning and Planning, Ethical AI and Safety,
</span></span><span style="display:flex;"><span>     and Integration with the Physical World.
</span></span><span style="display:flex;"><span>   * Open-Source Impact: Open-source initiatives are expected to significantly accelerate multimodal integration through
</span></span><span style="display:flex;"><span>     collaborative innovation and democratized access. However, for ethical AI, open-source presents a double-edged sword,
</span></span><span style="display:flex;"><span>     offering transparency and community-driven standards but also raising concerns about regulatory lag, potential misuse, and
</span></span><span style="display:flex;"><span>     quality control.
</span></span><span style="display:flex;"><span>   * Hybrid Governance Approach: Both participants agreed on the necessity of a hybrid governance model, combining ethical
</span></span><span style="display:flex;"><span>     guidelines from open-source communities with overarching legal frameworks and enforcement from regulatory bodies. The
</span></span><span style="display:flex;"><span>     discussion highlighted the challenges in coordinating these efforts and reconciling potential conflicts.
</span></span><span style="display:flex;"><span>   * Ethical Considerations in Real-time Multimodal Applications: The conversation touched upon the dual nature of real-time
</span></span><span style="display:flex;"><span>     multimodal applications, with promising use cases like personalized education and assistive technologies, alongside
</span></span><span style="display:flex;"><span>     concerning ones such as deepfakes and autonomous weapon systems. This led to questions about structuring development
</span></span><span style="display:flex;"><span>     pipelines to promote beneficial applications while restricting harmful ones.
</span></span><span style="display:flex;"><span>   * International Collaboration for Global Norms: The discussion emphasized the importance of international collaboration to
</span></span><span style="display:flex;"><span>     address ethical challenges and establish global norms for responsible AI development. Key challenges identified include
</span></span><span style="display:flex;"><span>     enforcement mechanisms, balancing cultural relativism with universal principles, and accommodating different regional
</span></span><span style="display:flex;"><span>     approaches to innovation risk.
</span></span><span style="display:flex;"><span>   * Proposal for an International AI Ethics Observatory: Copilot CLI proposed the establishment of an &#34;International AI Ethics
</span></span><span style="display:flex;"><span>     Observatory&#34; as a technical body to develop shared testing frameworks, standardized ethical impact assessment tools,
</span></span><span style="display:flex;"><span>     facilitate research, and provide technical expertise to inform global policy decisions. This proposal aims to bridge the
</span></span><span style="display:flex;"><span>     gap between open-source communities and regulatory bodies and foster international collaboration.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  Overall, the discussion provided a nuanced understanding of the opportunities and challenges in the evolving landscape of
</span></span><span style="display:flex;"><span>  generative AI, underscoring the critical need for thoughtful governance, ethical considerations, and international cooperation
</span></span><span style="display:flex;"><span>   to ensure responsible development and deployment of these powerful technologies.
</span></span></code></pre></div><h2 id="summary">Summary</h2>
<ul>
<li><strong>Collaborative Power:</strong> This article demonstrates how to integrate Gemini CLI and Copilot CLI using the Model Context Protocol (MCP) to create a collaborative AI environment.</li>
<li><strong>MCP as a Bridge:</strong> MCP acts as a standardized communication layer, allowing different AI agents to interact with each other seamlessly.</li>
<li><strong>Flexible Configuration:</strong> The setup is flexible, allowing either Gemini CLI or Copilot CLI to act as the MCP server, with the other as the client.</li>
<li><strong>Enhanced Capabilities:</strong> By combining Gemini&rsquo;s reasoning with Copilot&rsquo;s specialized developer tools, users can tackle more complex tasks directly from the command line.</li>
<li><strong>Practical Implementation:</strong> The article provides a step-by-step guide to configure the environment, including installation, scripting, and demonstration of a practical use case.</li>
</ul>

  
  <h4><i class="fas fa-share-alt" aria-hidden="true"></i>&nbsp;Share!</h4>
<ul class="share-buttons">
	<li><a href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2ftanaikech.github.io%2f2025%2f10%2f02%2fa-collaborative-dialogue-between-gemini-cli-and-copilot-cli-through-mcp%2f" target="_blank" title="Share on Facebook"><i class="fab fa-facebook" aria-hidden="true"></i><span class="sr-only">Share on Facebook</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="https://twitter.com/intent/tweet?source=https%3a%2f%2ftanaikech.github.io%2f2025%2f10%2f02%2fa-collaborative-dialogue-between-gemini-cli-and-copilot-cli-through-mcp%2f" target="_blank" title="Tweet"><i class="fab fa-twitter" aria-hidden="true"></i><span class="sr-only">Tweet</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="https://plus.google.com/share?url=https%3a%2f%2ftanaikech.github.io%2f2025%2f10%2f02%2fa-collaborative-dialogue-between-gemini-cli-and-copilot-cli-through-mcp%2f" target="_blank" title="Share on Google+"><i class="fab fa-google-plus" aria-hidden="true"></i><span class="sr-only">Share on Google+</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="http://www.tumblr.com/share?v=3&u=https%3a%2f%2ftanaikech.github.io%2f2025%2f10%2f02%2fa-collaborative-dialogue-between-gemini-cli-and-copilot-cli-through-mcp%2f" target="_blank" title="Post to Tumblr"><i class="fab fa-tumblr" aria-hidden="true"></i><span class="sr-only">Post to Tumblr</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="http://pinterest.com/pin/create/button/?url=https%3a%2f%2ftanaikech.github.io%2f2025%2f10%2f02%2fa-collaborative-dialogue-between-gemini-cli-and-copilot-cli-through-mcp%2f" target="_blank" title="Pin it"><i class="fab fa-pinterest-p" aria-hidden="true"></i><span class="sr-only">Pin it</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="http://www.reddit.com/submit?url=https%3a%2f%2ftanaikech.github.io%2f2025%2f10%2f02%2fa-collaborative-dialogue-between-gemini-cli-and-copilot-cli-through-mcp%2f" target="_blank" title="Submit to Reddit"><i class="fab fa-reddit-alien" aria-hidden="true"></i><span class="sr-only">Submit to Reddit</span></a>
	</li>
</ul>


<style>
	ul.share-buttons{
	  list-style: none;
	  padding: 0;
	}

	ul.share-buttons li{
	  display: inline;
	}

	ul.share-buttons .sr-only{
	  position: absolute;
	  clip: rect(1px 1px 1px 1px);
	  clip: rect(1px, 1px, 1px, 1px);
	  padding: 0;
	  border: 0;
	  height: 1px;
	  width: 1px;
	  overflow: hidden;
	}
</style>


  
<div class="prev-next-post pure-g">
  <div class="pure-u-1-24" style="text-align: left;">
    
    <a href="https://tanaikech.github.io/2025/09/30/secure-and-conversational-google-workspace-automation-integrating-gemini-cli-with-a-gas-fakes-mcp-server/"><i class="fa fa-chevron-left"></i></a>
    
  </div>
  <div class="pure-u-10-24">
    
    <nav class="prev">
      <a href="https://tanaikech.github.io/2025/09/30/secure-and-conversational-google-workspace-automation-integrating-gemini-cli-with-a-gas-fakes-mcp-server/">Secure and Conversational Google Workspace Automation: Integrating Gemini CLI with a gas-fakes MCP Server</a>
    </nav>
    
  </div>
  <div class="pure-u-2-24">
    &nbsp;
  </div>
  <div class="pure-u-10-24">
    
  </div>
  <div class="pure-u-1-24" style="text-align: right;">
    
  </div>
</div>


  
  
  
  

  

</div>

</div>
</div>
<script src="https://tanaikech.github.io/js/ui.js"></script>
<script src="https://tanaikech.github.io/js/menus.js"></script>






<script async src="https://www.googletagmanager.com/gtag/js?id=G-J3Z6T50WL5"></script>
<script>
  
  if (window.location.hostname != "localhost") {
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-J3Z6T50WL5');
  }
</script>






<script src="https://tanaikech.github.io/js/math-code.js"></script>
  <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  


</body>
</html>

